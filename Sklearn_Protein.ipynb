{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUJET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous prévoyez des étiquettes de localisation des organites de protéines pour chaque échantillon. Au total, 28 étiquettes différentes sont présentes dans l'ensemble de données. L'ensemble de données est acquis de manière hautement normalisée en utilisant une modalité d'imagerie (microscopie confocale). Cependant, l'ensemble de données comprend 27 types de cellules de morphologie très différente, qui affectent les profils protéiques des différents organites. Tous les échantillons d'images sont représentés par quatre filtres (stockés sous forme de fichiers individuels), la protéine d'intérêt (vert) et trois repères cellulaires: noyau (bleu), microtubules (rouge), réticulum endoplasmique (jaune). Le filtre vert devrait donc être utilisé pour prédire l'étiquette, et les autres filtres sont utilisés comme références."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.  Nucleoplasm  \n",
    "1.  Nuclear membrane   \n",
    "2.  Nucleoli   \n",
    "3.  Nucleoli fibrillar center   \n",
    "4.  Nuclear speckles   \n",
    "5.  Nuclear bodies   \n",
    "6.  Endoplasmic reticulum   \n",
    "7.  Golgi apparatus   \n",
    "8.  Peroxisomes   \n",
    "9.  Endosomes   \n",
    "10.  Lysosomes   \n",
    "11.  Intermediate filaments   \n",
    "12.  Actin filaments   \n",
    "13.  Focal adhesion sites   \n",
    "14.  Microtubules   \n",
    "15.  Microtubule ends   \n",
    "16.  Cytokinetic bridge   \n",
    "17.  Mitotic spindle   \n",
    "18.  Microtubule organizing center   \n",
    "19.  Centrosome   \n",
    "20.  Lipid droplets   \n",
    "21.  Plasma membrane   \n",
    "22.  Cell junctions   \n",
    "23.  Mitochondria   \n",
    "24.  Aggresome   \n",
    "25.  Cytosol   \n",
    "26.  Cytoplasmic bodies   \n",
    "27.  Rods & rings  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from skimage.io import imread\n",
    "import cv2\n",
    "from skimage.transform import resize\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from skimage.filters import try_all_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('./Data/train100.csv', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images=[imread('./Data/train/'+x+'_green.png', as_gray=True) for x in df.index]\n",
    "print(images[0].shape)\n",
    "df['Image']=images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Green_IMAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = try_all_threshold(df.iloc[0, 1], figsize=(10, 8), verbose=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape=[1, 5]\n",
    "fig=plt.figure(figsize=(20, 35))\n",
    "for i in range(shape[0]*shape[1]):\n",
    "    sub=plt.subplot(shape[0], shape[1], i+1)\n",
    "    plt.imshow(df.iloc[i, 1])\n",
    "#print('Example Images')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Hist']=df['Image'].apply(lambda x: np.histogram(x, 128)[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "clusters=10\n",
    "kmeans=KMeans(clusters)\n",
    "df['Cluster']=kmeans.fit_predict([np.array(x) for x in df['Hist'].values])\n",
    "df.head()\n",
    "shape=[1, 5]\n",
    "fig=plt.figure(figsize=(20, 35))\n",
    "for i in range(shape[0]*shape[1]):\n",
    "    sub=plt.subplot(shape[0], shape[1], i+1)\n",
    "    sub.set_title(df.iloc[i, 3])\n",
    "    plt.imshow(df.iloc[i, 1])\n",
    "print('Example Images')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load image\n",
    "data_train_dir = './Data/train100'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions for visualization\n",
    "def make_rgb_image_from_four_channels(channels: list, image_width=512, image_height=512) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    It makes literally RGB image from source four channels, \n",
    "    where yellow image will be yellow color, red will be red and so on  \n",
    "    \"\"\"\n",
    "    rgb_image = np.zeros(shape=(image_height, image_width, 3), dtype=np.float)\n",
    "    yellow = np.array(Image.open(channels[0]))\n",
    "    # yellow is red + green\n",
    "    rgb_image[:, :, 0] += yellow/2   \n",
    "    rgb_image[:, :, 1] += yellow/2\n",
    "    # loop for R,G and B channels\n",
    "    for index, channel in enumerate(channels[1:]):\n",
    "        current_image = Image.open(channel)\n",
    "        rgb_image[:, :, index] += current_image\n",
    "    # Normalize image\n",
    "    rgb_image = rgb_image / rgb_image.max() * 255\n",
    "    return rgb_image.astype(np.uint8)\n",
    "\n",
    "def visualize_part(start_class_index=0, nrows=4, ncols=3):\n",
    "    \"\"\"\n",
    "    Visualize the part of classes, started from class with index start_class_index,\n",
    "    make nrows classes, ncols examples for each one\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(nrows = nrows, ncols=ncols, figsize=(15, 25))\n",
    "    for class_index in range(nrows):\n",
    "        current_index = class_index + start_class_index\n",
    "        for sample in range(ncols):\n",
    "            current_part = train_df[train_df[index_class_dict[current_index]] == 1] \n",
    "            # 0 index is id\n",
    "            random_index = np.random.choice(current_part.values.shape[0], 1, replace=False)\n",
    "            # random line from data with selected class\n",
    "            current_line = current_part.values[random_index][0]\n",
    "            image_names = [os.path.join(data_train_dir, current_line[0]) \n",
    "                           + x + '.png' for x in channels]\n",
    "            rgb_image = make_rgb_image_from_four_channels(image_names)\n",
    "            # text annotations, main title and subclasses (may be empty in case one label)\n",
    "            main_class = index_class_dict[current_index]+'\\n'\n",
    "            # 2 index is vector with classes, split version of Target col\n",
    "            other_classes = [index_class_dict[x] for x in current_line[2] \n",
    "                             if x != (current_index)]\n",
    "            subtitle = ', '.join(other_classes)\n",
    "            # show image\n",
    "            ax[class_index, sample].set_title(main_class, fontsize=18)\n",
    "            ax[class_index, sample].text(250, -10, subtitle, \n",
    "                                         fontsize=14, horizontalalignment='center')\n",
    "            ax[class_index, sample].imshow(rgb_image)\n",
    "            ax[class_index, sample].set_xticklabels([])\n",
    "            ax[class_index, sample].set_yticklabels([])\n",
    "            ax[class_index, sample].tick_params(left=False, bottom=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize 3 examples for each class (4*3)\n",
    "visualize_part(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class study\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import os\n",
    "from itertools import chain\n",
    "from collections import Counter\n",
    "sns.set_style(\"white\")\n",
    "sns.set_context(\"notebook\", font_scale=1.5, rc={\"lines.linewidth\": 2.5})\n",
    "\n",
    "#from keras.preprocessing.image import load_img\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./Data/train.csv')\n",
    "def count_target(target_val):\n",
    "    return len(target_val.split(' '))\n",
    "\n",
    "df['nclass'] = df.Target.map(count_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for plotting the images\n",
    "\n",
    "def plot_img(img_id):\n",
    "    filt_no = 0\n",
    "    plt.figure(figsize=(30,60))\n",
    "    plt.tight_layout()\n",
    "    for filt in img_filt:\n",
    "        img_path = train_img_path + img_id + filt\n",
    "        img = np.array(load_img(img_path))\n",
    "        plt.subplot(1,4,filt_no+1)\n",
    "        plt.imshow(img)\n",
    "        if i==0: plt.title(filt[1:-4]+' filter')\n",
    "        plt.axis('off')\n",
    "        filt_no += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Label Count Distribribution\n",
    "\n",
    "label_count = []\n",
    "for i in range(df.nclass.min(),df.nclass.max()+1):\n",
    "    label_count.append(np.sum(df.nclass==i))\n",
    "    print('No. of images with',i,'label:',label_count[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(len(label_count))+1\n",
    "plt.bar(x,label_count)\n",
    "plt.title('Label Count Distribution in Train Set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mapping the labels\n",
    "\n",
    "def mk_list(val):\n",
    "    return [int(label) for label in val.split(' ')]\n",
    "df['target_list'] = df['Target'].map(mk_list)\n",
    "all_labels = list(chain.from_iterable(df['target_list'].values))\n",
    "label_count = Counter(all_labels)\n",
    "arr = np.zeros((28,))\n",
    "for key,value in label_count.items():\n",
    "    arr[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_class_labels = {0:  'Nucleoplasm',\n",
    "1:  'Nuclear membrane',\n",
    "2:  'Nucleoli',\n",
    "3:  'Nucleoli fibrillar center',\n",
    "4:  'Nuclear speckles',\n",
    "5:  'Nuclear bodies',\n",
    "6: 'Endoplasmic reticulum',\n",
    "7:  'Golgi apparatus',\n",
    "8:  'Peroxisomes',\n",
    "9:  'Endosomes',\n",
    "10:  'Lysosomes',\n",
    "11:  'Intermediate filaments',\n",
    "12:  'Actin filaments',\n",
    "13:  'Focal adhesion sites',\n",
    "14: 'Microtubules',\n",
    "15: 'Microtubule ends',\n",
    "16: 'Cytokinetic bridge',\n",
    "17: 'Mitotic spindle',\n",
    "18: 'Microtubule organizing center',\n",
    "19: 'Centrosome',\n",
    "20: 'Lipid droplets',\n",
    "21: 'Plasma membrane',\n",
    "22: 'Cell junctions',\n",
    "23: 'Mitochondria',\n",
    "24: 'Aggresome',\n",
    "25: 'Cytosol',\n",
    "26: 'Cytoplasmic bodies',\n",
    "27: 'Rods and rings'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graph class \n",
    "\n",
    "plt.figure(figsize=(30,5))\n",
    "ax = sns.barplot(x=np.arange(28),y=arr)\n",
    "ax.set_xticklabels(list(map_class_labels.values()), fontsize=15, rotation=40, ha=\"right\")\n",
    "ax.set(xlabel='Classes', ylabel='Class Counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the image with the histogram\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "plt.gray()\n",
    "import skimage.filters\n",
    "import scipy.ndimage\n",
    "import sklearn.feature_extraction\n",
    "import sklearn.cluster\n",
    "import skimage.feature\n",
    "import skimage.transform\n",
    "import PIL\n",
    "import sys\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_file(filename):\n",
    "    image = plt.imread(filename)\n",
    "    hist = np.histogram(image - image.mean(),\n",
    "                        bins=np.arange(image.min(),\n",
    "                                       image.max(),\n",
    "                                       1/256))\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(8, 3))\n",
    "    \n",
    "    axes[0].imshow(image, interpolation='nearest')\n",
    "    axes[0].axis('off')\n",
    "    axes[0].set_title(filename[-20:])\n",
    "    \n",
    "    axes[1].plot(hist[1][:-1], hist[0], lw=2)\n",
    "    axes[1].set_title('histogram of gray values')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_file('./Data/train/002daad6-bbc9-11e8-b2bc-ac1f6b6435d0_red.png')\n",
    "plot_file('./Data/train/002daad6-bbc9-11e8-b2bc-ac1f6b6435d0_green.png')\n",
    "plot_file('./Data/train/002daad6-bbc9-11e8-b2bc-ac1f6b6435d0_blue.png')\n",
    "plot_file('./Data/train/002daad6-bbc9-11e8-b2bc-ac1f6b6435d0_yellow.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_file('./Data/train/002daad6-bbc9-11e8-b2bc-ac1f6b6435d0_red.png')\n",
    "plot_file('./Data/train/002daad6-bbc9-11e8-b2bc-ac1f6b6435d0_green.png')\n",
    "plot_file('./Data/train/002daad6-bbc9-11e8-b2bc-ac1f6b6435d0_blue.png')\n",
    "plot_file('./Data/train/002daad6-bbc9-11e8-b2bc-ac1f6b6435d0_yellow.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Other\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import itertools as itt\n",
    "import networkx as nx\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = pd.read_csv(\"./Data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = {\n",
    "    0:  \"Nucleoplasm\",  \n",
    "    1:  \"Nuclear membrane\",   \n",
    "    2:  \"Nucleoli\",   \n",
    "    3:  \"Nucleoli fibrillar center\",   \n",
    "    4:  \"Nuclear speckles\",\n",
    "    5:  \"Nuclear bodies\",   \n",
    "    6:  \"Endoplasmic reticulum\",   \n",
    "    7:  \"Golgi apparatus\",   \n",
    "    8:  \"Peroxisomes\",   \n",
    "    9:  \"Endosomes\",   \n",
    "    10:  \"Lysosomes\",   \n",
    "    11:  \"Intermediate filaments\",   \n",
    "    12:  \"Actin filaments\",   \n",
    "    13:  \"Focal adhesion sites\",   \n",
    "    14:  \"Microtubules\",   \n",
    "    15:  \"Microtubule ends\",   \n",
    "    16:  \"Cytokinetic bridge\",   \n",
    "    17:  \"Mitotic spindle\",   \n",
    "    18:  \"Microtubule organizing center\",   \n",
    "    19:  \"Centrosome\",   \n",
    "    20:  \"Lipid droplets\",   \n",
    "    21:  \"Plasma membrane\",   \n",
    "    22:  \"Cell junctions\",   \n",
    "    23:  \"Mitochondria\",   \n",
    "    24:  \"Aggresome\",   \n",
    "    25:  \"Cytosol\",   \n",
    "    26:  \"Cytoplasmic bodies\",   \n",
    "    27:  \"Rods & rings\"\n",
    "}\n",
    "\n",
    "reverse_train_labels = dict((v,k) for k,v in label_names.items())\n",
    "\n",
    "def fill_targets(row):\n",
    "    row.Target = np.array(row.Target.split(\" \")).astype(np.int)\n",
    "    for num in row.Target:\n",
    "        name = label_names[int(num)]\n",
    "        row.loc[name] = 1\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in label_names.keys():\n",
    "    train_labels[label_names[key]] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train_labels.apply(fill_targets, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_counts = train_labels.drop([\"Id\", \"Target\"],axis=1).sum(axis=0).sort_values(ascending=False)\n",
    "plt.figure(figsize=(15,15))\n",
    "sns.barplot(y=target_counts.index.values, x=target_counts.values, order=target_counts.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_counts.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels[\"number_of_targets\"] = train_labels.drop([\"Id\", \"Target\"],axis=1).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_perc = train_labels.groupby(\"number_of_targets\").count()['Id']\n",
    "count_perc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.pie(count_perc,\n",
    "        labels=[\"%d targets\" % x for x in count_perc.index],\n",
    "        autopct='%1.1f%%')\n",
    "plt.ylabel('');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Other\n",
    "GAUSSIAN_NOISE = 0.1\n",
    "UPSAMPLE_MODE = 'SIMPLE'\n",
    "# number of validation images to use\n",
    "VALID_IMG_COUNT = 1000\n",
    "# maximum number of training images\n",
    "MAX_TRAIN_IMAGES = 15000 \n",
    "BASE_MODEL='RESNET52' # ['VGG16', 'RESNET52', 'InceptionV3', 'Xception', 'DenseNet169', 'DenseNet121']\n",
    "IMG_SIZE = (299, 299) # [(224, 224), (384, 384), (512, 512), (640, 640)]\n",
    "BATCH_SIZE = 32 # [1, 8, 16, 24]\n",
    "DROPOUT = 0.5\n",
    "DENSE_COUNT = 128\n",
    "LEARN_RATE = 1e-4\n",
    "EPOCHS = 10\n",
    "RGB_FLIP = 1 # should rgb be flipped when rendering images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from skimage.io import imread\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from skimage.util import montage\n",
    "montage_rgb = lambda x: np.stack([montage(x[:, :, :, i]) for i in range(x.shape[3])], -1)\n",
    "base_dir = './Data'\n",
    "train_image_dir = os.path.join(base_dir, 'train')\n",
    "test_image_dir = os.path.join(base_dir, 'test')\n",
    "import gc; gc.enable() # memory is tight\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_df = pd.read_csv(os.path.join('./Data/',\n",
    "                                 'train.csv'))\n",
    "print(image_df.shape[0], 'masks found')\n",
    "print(image_df['Id'].value_counts().shape[0])\n",
    "# just use green for now\n",
    "image_df['Green_path'] = image_df['Id'].map(lambda x: os.path.join(train_image_dir, '{}_green.png'.format(x)))\n",
    "image_df['Target_list'] = image_df['Target'].map(lambda x: [int(a) for a in x.split(' ')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "from collections import Counter\n",
    "all_labels = list(chain.from_iterable(image_df['Target_list'].values))\n",
    "c_val = Counter(all_labels)\n",
    "n_keys = c_val.keys()\n",
    "max_idx = max(n_keys)\n",
    "fig, ax1 = plt.subplots(1,1, figsize = (10, 5))\n",
    "ax1.bar(n_keys, [c_val[k] for k in n_keys])\n",
    "for k,v in c_val.items():\n",
    "    print(k, 'count:', v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a categorical vector\n",
    "image_df['Target_vec'] = image_df['Target_list'].map(lambda ck: [i in ck for i in range(max_idx+1)])\n",
    "image_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WHYNOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_df, valid_df = train_test_split(image_df, \n",
    "                 test_size = 0.3, \n",
    "                  # hack to make stratification work                  \n",
    "                 stratify = image_df['Target'].map(lambda x: x[:3] if '27' not in x else '0'))\n",
    "print(train_df.shape[0], 'Training masks')\n",
    "print(valid_df.shape[0], 'Validation masks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.sample(min(MAX_TRAIN_IMAGES, train_df.shape[0])) # limit size of training set (otherwise it takes too long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (10, 5))\n",
    "train_sum_vec = np.sum(np.stack(train_df['Target_vec'].values, 0), 0)\n",
    "valid_sum_vec = np.sum(np.stack(valid_df['Target_vec'].values, 0), 0)\n",
    "ax1.bar(n_keys, [train_sum_vec[k] for k in n_keys])\n",
    "ax1.set_title('Training Distribution')\n",
    "ax2.bar(n_keys, [valid_sum_vec[k] for k in n_keys])\n",
    "ax2.set_title('Validation Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=imread('./Data/train/00070df0-bbc3-11e8-b2bc-ac1f6b6435d0_green.png', as_gray=True)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
