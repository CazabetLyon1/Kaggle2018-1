{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3c99eefdd6849eeaeb53d353a9fe00e5489918fb"
   },
   "source": [
    "# SUJET : Human Protein Atlas Image Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f6334ed2c340b7ea13253a608cec4a91b3ff03dc"
   },
   "source": [
    "Le but du projet est de prevoir des étiquettes de localisation des organites de protéines pour chaque échantillon. Au total, 28 étiquettes différentes sont présentes dans l'ensemble de données. L'ensemble de données est acquis de manière hautement normalisée en utilisant une modalité d'imagerie (microscopie confocale). Cependant, l'ensemble de données comprend 27 types de cellules de morphologie très différente, qui affectent les profils protéiques des différents organites. Tous les échantillons d'images sont représentés par quatre filtres (stockés sous forme de fichiers individuels), la protéine d'intérêt (vert) et trois repères cellulaires: noyau (bleu), microtubules (rouge), réticulum endoplasmique (jaune). Le filtre vert devrait donc être utilisé pour prédire l'étiquette, et les autres filtres sont utilisés comme références."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f7da40df92d689d529449b7d94d65d88bdd4a06d"
   },
   "source": [
    "0.  Nucleoplasm  \n",
    "1.  Nuclear membrane   \n",
    "2.  Nucleoli   \n",
    "3.  Nucleoli fibrillar center   \n",
    "4.  Nuclear speckles   \n",
    "5.  Nuclear bodies   \n",
    "6.  Endoplasmic reticulum   \n",
    "7.  Golgi apparatus   \n",
    "8.  Peroxisomes   \n",
    "9.  Endosomes   \n",
    "10.  Lysosomes   \n",
    "11.  Intermediate filaments   \n",
    "12.  Actin filaments   \n",
    "13.  Focal adhesion sites   \n",
    "14.  Microtubules   \n",
    "15.  Microtubule ends   \n",
    "16.  Cytokinetic bridge   \n",
    "17.  Mitotic spindle   \n",
    "18.  Microtubule organizing center   \n",
    "19.  Centrosome   \n",
    "20.  Lipid droplets   \n",
    "21.  Plasma membrane   \n",
    "22.  Cell junctions   \n",
    "23.  Mitochondria   \n",
    "24.  Aggresome   \n",
    "25.  Cytosol   \n",
    "26.  Cytoplasmic bodies   \n",
    "27.  Rods & rings  \n",
    "\n",
    "Image entrainement : 32 072\n",
    "Image suoumission : 11 702"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "395ab40f1ad6a71092bfacbbeeb354200adcb212"
   },
   "source": [
    "# IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "dc2a5db8c7b563187305ae9bb1455d0cc7025c0a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from skimage.io import imread\n",
    "import cv2\n",
    "from skimage.transform import resize\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from skimage.filters import try_all_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a87b0139829b80689db7657ea36afcab971ca9b5"
   },
   "source": [
    "**ANALYSE DE DONNEES **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "71ce00ffa6b5793547de853b3cf0a012d6b5c264"
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('../input/train.csv', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d6e8daf8d179f1ab6af2ed98037b66f867163f47"
   },
   "outputs": [],
   "source": [
    "images=[imread('../input/train/'+x+'_green.png', as_gray=True) for x in df.index]\n",
    "print(images[0].shape)\n",
    "df['Image']=images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "23c522140543af0dcd89146271dc7f1b8351465a"
   },
   "outputs": [],
   "source": [
    "fig, ax = try_all_threshold(df.iloc[0, 1], figsize=(10, 8), verbose=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ffa24dacb72d30015a0e487ae285290a47214028"
   },
   "outputs": [],
   "source": [
    "df['Hist']=df['Image'].apply(lambda x: np.histogram(x, 128)[0])\n",
    "#df.head()\n",
    "#Histogramme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "060ba0f5f171202e3494c16badc60fe115cef60e"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "clusters=10\n",
    "kmeans=KMeans(clusters)\n",
    "df['Cluster']=kmeans.fit_predict([np.array(x) for x in df['Hist'].values])\n",
    "df.head()\n",
    "shape=[1, 5]\n",
    "fig=plt.figure(figsize=(20, 35))\n",
    "for i in range(shape[0]*shape[1]):\n",
    "    sub=plt.subplot(shape[0], shape[1], i+1)\n",
    "    sub.set_title(df.iloc[i, 3])\n",
    "    plt.imshow(df.iloc[i, 1])\n",
    "print('Exemple images avec leurs classes respectives')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2ea2617ec3080f5c62d75a87ddaec1bbe5cbd274"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "data_train_dir = r'../input/train'\n",
    "answer_file_path = r'../input/train.csv'\n",
    "\n",
    "channels = ['_yellow', '_red', '_green', '_blue']\n",
    "\n",
    "index_class_dict = {\n",
    "    0: \"Nucleoplasm\",\n",
    "    1: \"Nuclear membrane\",\n",
    "    2: \"Nucleoli\",\n",
    "    3: \"Nucleoli fibrillar center\",\n",
    "    4: \"Nuclear speckles\",\n",
    "    5: \"Nuclear bodies\",\n",
    "    6: \"Endoplasmic reticulum\",\n",
    "    7: \"Golgi apparatus\",\n",
    "    8: \"Peroxisomes\",\n",
    "    9: \"Endosomes\",\n",
    "    10: \"Lysosomes\",\n",
    "    11: \"Intermediate filaments\",\n",
    "    12: \"Actin filaments\",\n",
    "    13: \"Focal adhesion sites\",\n",
    "    14: \"Microtubules\",\n",
    "    15: \"Microtubule ends\",\n",
    "    16: \"Cytokinetic bridge\",\n",
    "    17: \"Mitotic spindle\",\n",
    "    18: \"Microtubule organizing center\",\n",
    "    19: \"Centrosome\",\n",
    "    20: \"Lipid droplets\",\n",
    "    21: \"Plasma membrane\",\n",
    "    22: \"Cell junctions\",\n",
    "    23: \"Mitochondria\",\n",
    "    24: \"Aggresome\",\n",
    "    25: \"Cytosol\",\n",
    "    26: \"Cytoplasmic bodies\",\n",
    "    27: \"Rods & rings\"\n",
    "}\n",
    "\n",
    "train_df = pd.read_csv(answer_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "97d89084332ec485adf26908202e7d538401d0bd"
   },
   "outputs": [],
   "source": [
    "train_df[f'target_vec'] = train_df['Target'].map(lambda x: list(map(int, x.strip().split())))\n",
    "for i in range(28):\n",
    "    train_df[f'{index_class_dict[i]}'] = train_df['Target'].map(\n",
    "             lambda x: 1 if str(i) in x.strip().split() else 0)\n",
    "#train_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3bdd9c2303d8f720a48cc4cb494e114c9a54164b"
   },
   "source": [
    "**IMAGE EN RGBY**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d9b6bce8ec86919ecac4fd9d930e81b3dde8a503"
   },
   "outputs": [],
   "source": [
    "class_index = 1  # Nuclear membrane\n",
    "current_part = train_df[train_df[index_class_dict[class_index]] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "976225c4df9bc2735d160f4d72900809afdfe387"
   },
   "outputs": [],
   "source": [
    "#Functions for visualization\n",
    "def make_rgb_image_from_four_channels(channels: list, image_width=512, image_height=512) -> np.ndarray:\n",
    "    \"\"\"\n",
    "     On crée une immage RGBY à partir des 4 filtres\n",
    "      \n",
    "    \"\"\"\n",
    "    rgb_image = np.zeros(shape=(image_height, image_width, 3), dtype=np.float)\n",
    "    yellow = np.array(Image.open(channels[0]))\n",
    "    # yellow is red + green\n",
    "    rgb_image[:, :, 0] += yellow/2   \n",
    "    rgb_image[:, :, 1] += yellow/2\n",
    "    # loop for R,G and B channels\n",
    "    for index, channel in enumerate(channels[1:]):\n",
    "        current_image = Image.open(channel)\n",
    "        rgb_image[:, :, index] += current_image\n",
    "    # Normalize image\n",
    "    rgb_image = rgb_image / rgb_image.max() * 255\n",
    "    return rgb_image.astype(np.uint8)\n",
    "def visualize_part(start_class_index=0, nrows=4, ncols=3):\n",
    "    fig, ax = plt.subplots(nrows = nrows, ncols=ncols, figsize=(15, 25))\n",
    "    for class_index in range(nrows):\n",
    "        current_index = class_index + start_class_index\n",
    "        for sample in range(ncols):\n",
    "            current_part = train_df[train_df[index_class_dict[current_index]] == 1] \n",
    "            # 0 index is id\n",
    "            random_index = np.random.choice(current_part.values.shape[0], 1, replace=False)\n",
    "            # random line from data with selected class\n",
    "            current_line = current_part.values[random_index][0]\n",
    "            image_names = [os.path.join(data_train_dir, current_line[0]) \n",
    "                           + x + '.png' for x in channels]\n",
    "            rgb_image = make_rgb_image_from_four_channels(image_names)\n",
    "            # text annotations, main title and subclasses (may be empty in case one label)\n",
    "            main_class = index_class_dict[current_index]+'\\n'\n",
    "            # 2 index is vector with classes, split version of Target col\n",
    "            other_classes = [index_class_dict[x] for x in current_line[2] \n",
    "                             if x != (current_index)]\n",
    "            subtitle = ', '.join(other_classes)\n",
    "            # show image\n",
    "            ax[class_index, sample].set_title(main_class, fontsize=18)\n",
    "            ax[class_index, sample].text(250, -10, subtitle, \n",
    "                                         fontsize=14, horizontalalignment='center')\n",
    "            ax[class_index, sample].imshow(rgb_image)\n",
    "            ax[class_index, sample].set_xticklabels([])\n",
    "            ax[class_index, sample].set_yticklabels([])\n",
    "            ax[class_index, sample].tick_params(left=False, bottom=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5f644b34bab8f99ee00e6224228c46d22e0609a2"
   },
   "outputs": [],
   "source": [
    "#visualize 3 examples for each class (4*3)\n",
    "visualize_part(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "93908ee9718360b0958af7cb73a42ef76bd64e5b"
   },
   "outputs": [],
   "source": [
    "#class study\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import os\n",
    "from itertools import chain\n",
    "from collections import Counter\n",
    "sns.set_style(\"white\")\n",
    "sns.set_context(\"notebook\", font_scale=1.5, rc={\"lines.linewidth\": 2.5})\n",
    "\n",
    "#from keras.preprocessing.image import load_img\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "af85ef0e9a668c722ac1150a33064cb93d5fb627"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../input/train.csv')\n",
    "def count_target(target_val):\n",
    "    return len(target_val.split(' '))\n",
    "\n",
    "df['nclass'] = df.Target.map(count_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "da4c9a4a1f015bd073a6b933ae0c67c997739b42"
   },
   "outputs": [],
   "source": [
    "#Function for plotting the images\n",
    "\n",
    "def plot_img(img_id):\n",
    "    filt_no = 0\n",
    "    plt.figure(figsize=(30,60))\n",
    "    plt.tight_layout()\n",
    "    for filt in img_filt:\n",
    "        img_path = train_img_path + img_id + filt\n",
    "        img = np.array(load_img(img_path))\n",
    "        plt.subplot(1,4,filt_no+1)\n",
    "        plt.imshow(img)\n",
    "        if i==0: plt.title(filt[1:-4]+' filter')\n",
    "        plt.axis('off')\n",
    "        filt_no += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b97c7dcf5d338e4fb7d0f18eb8138b3296127300"
   },
   "outputs": [],
   "source": [
    "#Label Count Distribribution\n",
    "\n",
    "label_count = []\n",
    "for i in range(df.nclass.min(),df.nclass.max()+1):\n",
    "    label_count.append(np.sum(df.nclass==i))\n",
    "    print('No. of images with',i,'label:',label_count[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "684dd4cffeea0b1eb5c1597d58de1770bad0c560"
   },
   "outputs": [],
   "source": [
    "x = np.arange(len(label_count))+1\n",
    "plt.bar(x,label_count)\n",
    "plt.title('Distribution du nombre de classe par image' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "16a15d52207f7d63b3c849020075d94625bf9aa5"
   },
   "outputs": [],
   "source": [
    "#Plotting the image with the histogram\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "plt.gray()\n",
    "import skimage.filters\n",
    "import scipy.ndimage\n",
    "import sklearn.feature_extraction\n",
    "import sklearn.cluster\n",
    "import skimage.feature\n",
    "import skimage.transform\n",
    "import PIL\n",
    "import sys\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e3a2f0ab914865745bd4e7fd1eed7f31d6a4244f"
   },
   "outputs": [],
   "source": [
    "def plot_file(filename):\n",
    "    image = plt.imread(filename)\n",
    "    hist = np.histogram(image - image.mean(),\n",
    "                        bins=np.arange(image.min(),\n",
    "                                       image.max(),\n",
    "                                       1/256))\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(8, 3))\n",
    "    \n",
    "    axes[0].imshow(image, interpolation='nearest')\n",
    "    axes[0].axis('off')\n",
    "    axes[0].set_title(filename[-20:])\n",
    "    \n",
    "    axes[1].plot(hist[1][:-1], hist[0], lw=2)\n",
    "    axes[1].set_title('histogram of gray values')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4b811b3d0e34b4d2bd26e1fedad79f9e2460918c"
   },
   "outputs": [],
   "source": [
    "#plot_file('../input/train/002daad6-bbc9-11e8-b2bc-ac1f6b6435d0_red.png')\n",
    "#plot_file('../input/train/002daad6-bbc9-11e8-b2bc-ac1f6b6435d0_green.png')\n",
    "#plot_file('../input/train/002daad6-bbc9-11e8-b2bc-ac1f6b6435d0_blue.png')\n",
    "#plot_file('../input/train/002daad6-bbc9-11e8-b2bc-ac1f6b6435d0_yellow.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9fddf6293331264f3e52b1be34aec1e1ecae07eb"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import itertools as itt\n",
    "import networkx as nx\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2023dfb9d9d319e9214ce53a43143a806ff207c8"
   },
   "outputs": [],
   "source": [
    "train_labels = pd.read_csv(\"../input/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b3703b2490ac2888c10615f4987aca3ff74376da"
   },
   "outputs": [],
   "source": [
    "label_names = {\n",
    "    0:  \"Nucleoplasm\",  \n",
    "    1:  \"Nuclear membrane\",   \n",
    "    2:  \"Nucleoli\",   \n",
    "    3:  \"Nucleoli fibrillar center\",   \n",
    "    4:  \"Nuclear speckles\",\n",
    "    5:  \"Nuclear bodies\",   \n",
    "    6:  \"Endoplasmic reticulum\",   \n",
    "    7:  \"Golgi apparatus\",   \n",
    "    8:  \"Peroxisomes\",   \n",
    "    9:  \"Endosomes\",   \n",
    "    10:  \"Lysosomes\",   \n",
    "    11:  \"Intermediate filaments\",   \n",
    "    12:  \"Actin filaments\",   \n",
    "    13:  \"Focal adhesion sites\",   \n",
    "    14:  \"Microtubules\",   \n",
    "    15:  \"Microtubule ends\",   \n",
    "    16:  \"Cytokinetic bridge\",   \n",
    "    17:  \"Mitotic spindle\",   \n",
    "    18:  \"Microtubule organizing center\",   \n",
    "    19:  \"Centrosome\",   \n",
    "    20:  \"Lipid droplets\",   \n",
    "    21:  \"Plasma membrane\",   \n",
    "    22:  \"Cell junctions\",   \n",
    "    23:  \"Mitochondria\",   \n",
    "    24:  \"Aggresome\",   \n",
    "    25:  \"Cytosol\",   \n",
    "    26:  \"Cytoplasmic bodies\",   \n",
    "    27:  \"Rods & rings\"\n",
    "}\n",
    "\n",
    "#reverse_train_labels = dict((v,k) for k,v in label_names.items())\n",
    "\n",
    "def fill_targets(row):\n",
    "    row.Target = np.array(row.Target.split(\" \")).astype(np.int)\n",
    "    for num in row.Target:\n",
    "        name = label_names[int(num)]\n",
    "        row.loc[name] = 1\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "39941a3f288338c388a3529c167413fec5ff1157"
   },
   "outputs": [],
   "source": [
    "for key in label_names.keys():\n",
    "    train_labels[label_names[key]] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "22864f8b286e83f485402d40db8aebac2f7a70cb"
   },
   "outputs": [],
   "source": [
    "train_labels = train_labels.apply(fill_targets, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4d3064fdb8894d6297bb99a46117a59f4836da37"
   },
   "outputs": [],
   "source": [
    "target_counts = train_labels.drop([\"Id\", \"Target\"],axis=1).sum(axis=0).sort_values(ascending=False)\n",
    "plt.figure(figsize=(15,15))\n",
    "sns.barplot(y=target_counts.index.values, x=target_counts.values, order=target_counts.index)\n",
    "plt.title('Redondance des différentes classes ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b969d87ee2690b887778dac047dc7de4cf440fde"
   },
   "outputs": [],
   "source": [
    "print('Classes les moins répandu')\n",
    "target_counts.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e8911faa4ba71433d80623dea3f7973783c3f695"
   },
   "outputs": [],
   "source": [
    "train_labels[\"Nombre de Classe par Image\"] = train_labels.drop([\"Id\", \"Target\"],axis=1).sum(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cc041eaf5de6b48c42ccd6018887e9487fd3006d"
   },
   "outputs": [],
   "source": [
    "count_perc = train_labels.groupby(\"Nombre de Classe par Image\").count()['Id']\n",
    "count_perc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0cbae82e6948edad76ea2d5cf1d86d10baf29e03"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.pie(count_perc,\n",
    "        labels=[\"%d Classe\" % x for x in count_perc.index],\n",
    "        autopct='%1.1f%%')\n",
    "plt.ylabel('');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3bc744025a0b15f1da3cd10817a21144887f5b8a"
   },
   "source": [
    "**MISE EN PLACE DE LA SOLUTION**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2862100620fef682297b3de57aae5e96337692bc"
   },
   "source": [
    "**IMPORT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6847b86fbe8282f4b0276409ff1ccb7014d29327"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.utils import Sequence\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8ac473ffbcaf58973043fa3aaf1232f4393f5af2"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "SEED = 777\n",
    "SHAPE = (512, 512, 4) \n",
    "DIR = '../input'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5b4a7882da7c70c0ec41e270f17bcb757eb85bd6"
   },
   "source": [
    "** SEUIL DE VALIDATION **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3bf7d30a09e8b9b4fa086b471f58a183b828422f"
   },
   "outputs": [],
   "source": [
    "VAL_RATIO = 0.1 # 10 % de validation\n",
    "THRESHOLD = 0.5 # seuil de probabilité de prédire que l'image appartient à la classe \n",
    "ia.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "80170664e6b877fbca49aa0b41b16d0327b61d3c"
   },
   "outputs": [],
   "source": [
    "def getTrainDataset():\n",
    "    \n",
    "    path_to_train = DIR + '/train/'\n",
    "    data = pd.read_csv(DIR + '/train.csv')\n",
    "\n",
    "    paths = []\n",
    "    labels = []\n",
    "    \n",
    "    for name, lbl in zip(data['Id'], data['Target'].str.split(' ')):\n",
    "        y = np.zeros(28)\n",
    "        for key in lbl:\n",
    "            y[int(key)] = 1\n",
    "        paths.append(os.path.join(path_to_train, name))\n",
    "        labels.append(y)\n",
    "\n",
    "    return np.array(paths), np.array(labels)\n",
    "\n",
    "def getTestDataset():\n",
    "    \n",
    "    path_to_test = DIR + '/test/'\n",
    "    data = pd.read_csv(DIR + '/sample_submission.csv')\n",
    "\n",
    "    paths = []\n",
    "    labels = []\n",
    "    \n",
    "    for name in data['Id']:\n",
    "        y = np.ones(28)\n",
    "        paths.append(os.path.join(path_to_test, name))\n",
    "        labels.append(y)\n",
    "\n",
    "    return np.array(paths), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cf872dfd884a8c6c737d5fe7aba45b7ab5021ab7"
   },
   "outputs": [],
   "source": [
    "class ProteinDataGenerator(keras.utils.Sequence):\n",
    "            \n",
    "    def __init__(self, paths, labels, batch_size, shape, shuffle = False, use_cache = False, augment = False):\n",
    "        self.paths, self.labels = paths, labels\n",
    "        self.batch_size = batch_size\n",
    "        self.shape = shape\n",
    "        self.shuffle = shuffle\n",
    "        self.use_cache = use_cache\n",
    "        self.augment = augment\n",
    "        if use_cache == True:\n",
    "            self.cache = np.zeros((paths.shape[0], shape[0], shape[1], shape[2]), dtype=np.float16)\n",
    "            self.is_cached = np.zeros((paths.shape[0]))\n",
    "        self.on_epoch_end()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.paths) / float(self.batch_size)))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        indexes = self.indexes[idx * self.batch_size : (idx+1) * self.batch_size]\n",
    "\n",
    "        paths = self.paths[indexes]\n",
    "        X = np.zeros((paths.shape[0], self.shape[0], self.shape[1], self.shape[2]))\n",
    "        # Generate data\n",
    "        if self.use_cache == True:\n",
    "            X = self.cache[indexes]\n",
    "            for i, path in enumerate(paths[np.where(self.is_cached[indexes] == 0)]):\n",
    "                image = self.__load_image(path)\n",
    "                self.is_cached[indexes[i]] = 1\n",
    "                self.cache[indexes[i]] = image\n",
    "                X[i] = image\n",
    "        else:\n",
    "            for i, path in enumerate(paths):\n",
    "                X[i] = self.__load_image(path)\n",
    "\n",
    "        y = self.labels[indexes]\n",
    "                \n",
    "        if self.augment == True:\n",
    "            seq = iaa.Sequential([\n",
    "                iaa.OneOf([\n",
    "                    iaa.Fliplr(0.5), # horizontal flips\n",
    "                    iaa.Crop(percent=(0, 0.1)), # random crops\n",
    "                    # Small gaussian blur with random sigma between 0 and 0.5.\n",
    "                    # But we only blur about 50% of all images.\n",
    "                    iaa.Sometimes(0.5,\n",
    "                        iaa.GaussianBlur(sigma=(0, 0.5))\n",
    "                    ),\n",
    "                    # Strengthen or weaken the contrast in each image.\n",
    "                    iaa.ContrastNormalization((0.75, 1.5)),\n",
    "                    # Add gaussian noise.\n",
    "                    # For 50% of all images, we sample the noise once per pixel.\n",
    "                    # For the other 50% of all images, we sample the noise per pixel AND\n",
    "                    # channel. This can change the color (not only brightness) of the\n",
    "                    # pixels.\n",
    "                    iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255), per_channel=0.5),\n",
    "                    # Make some images brighter and some darker.\n",
    "                    # In 20% of all cases, we sample the multiplier once per channel,\n",
    "                    # which can end up changing the color of the images.\n",
    "                    iaa.Multiply((0.8, 1.2), per_channel=0.2),\n",
    "                    # Apply affine transformations to each image.\n",
    "                    # Scale/zoom them, translate/move them, rotate them and shear them.\n",
    "                    iaa.Affine(\n",
    "                        scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)},\n",
    "                        translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n",
    "                        rotate=(-180, 180),\n",
    "                        shear=(-8, 8)\n",
    "                    )\n",
    "                ])], random_order=True)\n",
    "\n",
    "            X = np.concatenate((X, seq.augment_images(X), seq.augment_images(X), seq.augment_images(X)), 0)\n",
    "            y = np.concatenate((y, y, y, y), 0)\n",
    "        \n",
    "        return X, y\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        \n",
    "        # Updates indexes after each epoch\n",
    "        self.indexes = np.arange(len(self.paths))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"Create a generator that iterate over the Sequence.\"\"\"\n",
    "        for item in (self[i] for i in range(len(self))):\n",
    "            yield item\n",
    "            \n",
    "    #Load the images in RGBY\n",
    "    def __load_image(self, path):\n",
    "        R = Image.open(path + '_red.png')\n",
    "        G = Image.open(path + '_green.png')\n",
    "        B = Image.open(path + '_blue.png')\n",
    "        Y = Image.open(path + '_yellow.png')\n",
    "\n",
    "        im = np.stack((\n",
    "            np.array(R), \n",
    "            np.array(G), \n",
    "            np.array(B),\n",
    "            np.array(Y)), -1)\n",
    "        \n",
    "        im = cv2.resize(im, (SHAPE[0], SHAPE[1]))\n",
    "        im = np.divide(im, 255)\n",
    "        return im"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "106a6bf5c5173117b097d7f8392a8eb52d883bef"
   },
   "source": [
    "**Keras**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d2d1094f9cb5c4e321797144129aba03eeb35299"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, Input, Conv2D, MaxPooling2D, BatchNormalization, Concatenate, ReLU, LeakyReLU, GlobalAveragePooling2D\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "from keras import metrics\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as K\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2e2515b7cb27e72e75ddd70d7ad94cfa598add36"
   },
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    #y_pred = K.round(y_pred)\n",
    "    #y_pred = K.cast(K.greater(K.clip(y_pred, 0, 1), THRESHOLD), K.floatx())\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "def f1_loss(y_true, y_pred):\n",
    "    \n",
    "    #y_pred = K.cast(K.greater(K.clip(y_pred, 0, 1), THRESHOLD), K.floatx())\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return 1-K.mean(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "995a8867ed83293063ec5cb247add78c454eac24"
   },
   "source": [
    "**CREATION DU MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e6d4f73e9699022fbf6127fbab3044a933a48269"
   },
   "outputs": [],
   "source": [
    "def create_model(input_shape):\n",
    "    \n",
    "    dropRate = 0.25\n",
    "    \n",
    "    init = Input(input_shape)\n",
    "    x = BatchNormalization(axis=-1)(init)\n",
    "    x = Conv2D(32, (3, 3))(x) #, strides=(2,2))(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    ginp1 = Dropout(dropRate)(x)\n",
    "    \n",
    "    x = BatchNormalization(axis=-1)(ginp1)\n",
    "    x = Conv2D(64, (3, 3), strides=(2,2))(x)\n",
    "    x = ReLU()(x)\n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "    x = Conv2D(64, (3, 3))(x)\n",
    "    x = ReLU()(x)\n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "    x = Conv2D(64, (3, 3))(x)\n",
    "    x = ReLU()(x)\n",
    "    \n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    ginp2 = Dropout(dropRate)(x)\n",
    "    \n",
    "    x = BatchNormalization(axis=-1)(ginp2)\n",
    "    x = Conv2D(128, (3, 3))(x)\n",
    "    x = ReLU()(x)\n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "    x = Conv2D(128, (3, 3))(x)\n",
    "    x = ReLU()(x)\n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "    x = Conv2D(128, (3, 3))(x)\n",
    "    x = ReLU()(x)\n",
    "    ginp3 = Dropout(dropRate)(x)\n",
    "    \n",
    "    gap1 = GlobalAveragePooling2D()(ginp1)\n",
    "    gap2 = GlobalAveragePooling2D()(ginp2)\n",
    "    gap3 = GlobalAveragePooling2D()(ginp3)\n",
    "    \n",
    "    x = Concatenate()([gap1, gap2, gap3])\n",
    "    \n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(dropRate)(x)\n",
    "    \n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    \n",
    "    x = Dense(28)(x)\n",
    "    x = Activation('sigmoid')(x)\n",
    "    \n",
    "    model = Model(init, x)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "931cc977f6630023b7512d077df7ad7f83cc02b8"
   },
   "outputs": [],
   "source": [
    "model = create_model(SHAPE)\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=Adam(1e-03),\n",
    "    metrics=['acc',f1])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0bd66cf27ffd7c7ff22b4024af81a6b24d9f0466"
   },
   "outputs": [],
   "source": [
    "paths, labels = getTrainDataset()\n",
    "\n",
    "# divide to \n",
    "keys = np.arange(paths.shape[0], dtype=np.int)  \n",
    "np.random.seed(SEED)\n",
    "np.random.shuffle(keys)\n",
    "lastTrainIndex = int((1-VAL_RATIO) * paths.shape[0])\n",
    "\n",
    "pathsTrain = paths[0:lastTrainIndex]\n",
    "labelsTrain = labels[0:lastTrainIndex]\n",
    "pathsVal = paths[lastTrainIndex:]\n",
    "labelsVal = labels[lastTrainIndex:]\n",
    "\n",
    "print(paths.shape, labels.shape)\n",
    "print(pathsTrain.shape, labelsTrain.shape, pathsVal.shape, labelsVal.shape)\n",
    "\n",
    "tg = ProteinDataGenerator(pathsTrain, labelsTrain, BATCH_SIZE, SHAPE, use_cache=False, augment = False, shuffle = False)\n",
    "vg = ProteinDataGenerator(pathsVal, labelsVal, BATCH_SIZE, SHAPE, use_cache=False, shuffle = False)\n",
    "\n",
    "checkpoint = ModelCheckpoint('./base.model', monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='min', period=1)\n",
    "reduceLROnPlato = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fc21bed1bb33d2c2471e25ca40289d5acadaaeae"
   },
   "outputs": [],
   "source": [
    "use_multiprocessing = False \n",
    "workers = 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6697323fcbb179b9eabbd54ce63a58f7a4fb5808"
   },
   "source": [
    "**ENTRAINEMENT DU MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "807268787e91fc3b99cf3a6634d10932c4d63e07"
   },
   "outputs": [],
   "source": [
    "\"\"\"\"\n",
    "epochs = 4\n",
    "\n",
    "hist = model.fit_generator(\n",
    "    tg,\n",
    "    steps_per_epoch=len(tg),\n",
    "    validation_data=vg,\n",
    "    validation_steps=8,\n",
    "    epochs=epochs,\n",
    "    use_multiprocessing=use_multiprocessing,\n",
    "    workers=workers,\n",
    "    verbose=1,\n",
    "    callbacks=[checkpoint])\n",
    "\"\"\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1fe75c98b6cab3b6ee7f2082f47b8d15bcc7ce89"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(15,5))\n",
    "ax[0].set_title('loss')\n",
    "ax[0].plot(hist.epoch, hist.history[\"loss\"], label=\"Train loss\")\n",
    "ax[0].plot(hist.epoch, hist.history[\"val_loss\"], label=\"Validation loss\")\n",
    "ax[1].set_title('acc')\n",
    "ax[1].plot(hist.epoch, hist.history[\"f1\"], label=\"Train F1\")\n",
    "ax[1].plot(hist.epoch, hist.history[\"val_f1\"], label=\"Validation F1\")\n",
    "ax[0].legend()\n",
    "ax[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d715154fbdc67a8bdb2b3b795433ce8bb3da2308"
   },
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "model.layers[-1].trainable = True\n",
    "model.layers[-2].trainable = True\n",
    "model.layers[-3].trainable = True\n",
    "model.layers[-4].trainable = True\n",
    "model.layers[-5].trainable = True\n",
    "model.layers[-6].trainable = True\n",
    "model.layers[-7].trainable = True\n",
    "\n",
    "model.compile(loss=f1_loss,\n",
    "            optimizer=Adam(lr=1e-4),\n",
    "            metrics=['accuracy', f1])\n",
    "\n",
    "model.fit_generator(\n",
    "    tg,\n",
    "    steps_per_epoch=len(tg),\n",
    "    validation_data=vg,\n",
    "    validation_steps=8,\n",
    "    epochs=1,\n",
    "    use_multiprocessing=use_multiprocessing, # you have to train the model on GPU in order to this to be benefitial\n",
    "    workers=workers, # you have to train the model on GPU in order to this to be benefitial\n",
    "    verbose=1,\n",
    "    max_queue_size=4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d140cd45cc57a3360ec921c34b7f7f38aadc95bc"
   },
   "source": [
    "**VALIDATION**\n",
    "\n",
    "Choisir le seuil de prédiction approprié maximisant le score de validation F1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f94873e412a61c728ac539dd756334e9e31b2f4d"
   },
   "outputs": [],
   "source": [
    "bestModel = load_model('./base.model', custom_objects={'f1': f1})\n",
    "#bestModel = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "210fbd7154d372688f5feb382b7fea3b9c2c6aa9"
   },
   "outputs": [],
   "source": [
    "fullValGen = vg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3cf357f85b5f467743858c64af154accba271a64"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score as off1\n",
    "\n",
    "def getOptimalT(mdl, fullValGen):\n",
    "    \n",
    "    lastFullValPred = np.empty((0, 28))\n",
    "    lastFullValLabels = np.empty((0, 28))\n",
    "    for i in tqdm(range(len(fullValGen))): \n",
    "        im, lbl = fullValGen[i]\n",
    "        scores = mdl.predict(im)\n",
    "        lastFullValPred = np.append(lastFullValPred, scores, axis=0)\n",
    "        lastFullValLabels = np.append(lastFullValLabels, lbl, axis=0)\n",
    "    print(lastFullValPred.shape, lastFullValLabels.shape)\n",
    "    \n",
    "    rng = np.arange(0, 1, 0.001)\n",
    "    f1s = np.zeros((rng.shape[0], 28))\n",
    "    for j,t in enumerate(tqdm(rng)):\n",
    "        for i in range(28):\n",
    "            p = np.array(lastFullValPred[:,i]>t, dtype=np.int8)\n",
    "            #scoref1 = K.eval(f1_score(fullValLabels[:,i], p, average='binary'))\n",
    "            scoref1 = off1(lastFullValLabels[:,i], p, average='binary')\n",
    "            f1s[j,i] = scoref1\n",
    "            \n",
    "    print(np.max(f1s, axis=0))\n",
    "    print(np.mean(np.max(f1s, axis=0)))\n",
    "    \n",
    "    plt.plot(rng, f1s)\n",
    "    T = np.empty(28)\n",
    "    for i in range(28):\n",
    "        T[i] = rng[np.where(f1s[:,i] == np.max(f1s[:,i]))[0][0]]\n",
    "    #print('Choosing threshold: ', T, ', validation F1-score: ', max(f1s))\n",
    "    print(T)\n",
    "    \n",
    "    return T, np.mean(np.max(f1s, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2b625b1775a938086de8c1bedb797f3f177d5612"
   },
   "outputs": [],
   "source": [
    "fullValGen = ProteinDataGenerator(paths[lastTrainIndex:], labels[lastTrainIndex:], BATCH_SIZE, SHAPE)\n",
    "print('Last model after fine-tuning')\n",
    "T1, ff1 = getOptimalT(model, fullValGen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "99ea924600d8bdd853d6ba6ef0856a3b02666090"
   },
   "outputs": [],
   "source": [
    "print('Best save model')\n",
    "T2, ff2 = getOptimalT(bestModel, fullValGen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c7827b48c446bb3f2b0b4ce185d4111dc2856b1e"
   },
   "outputs": [],
   "source": [
    "if ff1 > ff2:\n",
    "    T = T1\n",
    "    bestModel = model\n",
    "else:\n",
    "    T = T2\n",
    "    bestModel = bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5445f6218ab6893316caef3db3c407b6f68857e3"
   },
   "outputs": [],
   "source": [
    "pathsTest, labelsTest = getTestDataset()\n",
    "\n",
    "testg = ProteinDataGenerator(pathsTest, labelsTest, BATCH_SIZE, SHAPE)\n",
    "submit = pd.read_csv(DIR + '/sample_submission.csv')\n",
    "P = np.zeros((pathsTest.shape[0], 28))\n",
    "for i in tqdm(range(len(testg))):\n",
    "    images, labels = testg[i]\n",
    "    score = bestModel.predict(images)\n",
    "    P[i*BATCH_SIZE:i*BATCH_SIZE+score.shape[0]] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1b7a10cacfe7cd9f9ffb3300cd2b0b839bacd067"
   },
   "outputs": [],
   "source": [
    "PP = np.array(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e31d4a87e47b3626665316bf2de6943b914ebaa5"
   },
   "outputs": [],
   "source": [
    "prediction = []\n",
    "\n",
    "for row in tqdm(range(submit.shape[0])):\n",
    "    \n",
    "    str_label = ''\n",
    "    \n",
    "    for col in range(PP.shape[1]):\n",
    "        if(PP[row, col] < T[col]):\n",
    "            str_label += ''\n",
    "        else:\n",
    "            str_label += str(col) + ' '\n",
    "    prediction.append(str_label.strip())\n",
    "    \n",
    "submit['Predicted'] = np.array(prediction)\n",
    "submit.to_csv('RGBY_CNN.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
